{smcl}
{* *! version 0.13.10.22 22oct2013}{...}

{cmd:help parallel}
{hline}

{title:Title}

{phang}
{bf:parallel} {hline 2} Stata module for Parallel computing

{title:Syntax}

{pstd}Setting the number of clusters (data blocks)

{p 8 17 2}
{cmdab:parallel setclusters} # [, {opt f:orce} 
{opt s:tatadir}({it:{help filename:stata_path}})]

{pstd}Parallelizing a do-file

{p 8 17 2}
{cmdab:parallel do}
{it:{help filename}} [, {opt by}({it:{help varlist}}) {opt f:orce} {opt k:eep} {opt keepl:ast} {opt p:rograms} {opt m:ata} {opt nog:lobal} {opt s:eeds}({it:{help numlist}}) {opt nod:ata}
 {opt r:andtype}({it:{help strings:datetime|random.org}}) 
 {opt t:imeout}({it:integer}) 
 {opt pr:ocessors}({it:integer})]

{pstd}Parallelizing a stata command

{p 8 17 2}
{cmdab:parallel} [, {opt by}({it:{help varlist}}) {opt f:orce} {opt k:eep} {opt keepl:ast} {opt p:rograms} {opt m:ata} {opt nog:lobal} {opt s:eeds}({it:{help numlist}}) {opt nod:ata} 
 {opt r:andtype}({it:{help strings:datetime|random.org}}) 
 {opt t:imeout}({it:integer}) 
 {opt pr:ocessors}({it:integer})
 {opt keepu:sing}({it:{help varlist}})]:
{it:stata_cmd}

{pstd}Removing auxiliary files

{p 8 17 2}
{cmdab:parallel clean} [, {opt e:vent(pll_id)} {opt a:ll} {opt f:orce}]

{pstd}Query if the mother process has requested to break

{p 8 17 2}
{cmdab:parallel break}


{synoptset 13 tabbed}{...}
{synopthdr}
{synoptline}
{syntab:Setting the number of clusters}
{synopt:{opt f:orce}}In order to protect the users' computers, setting more than 8 
clusters it is not permitted (see the {err:WARNING} in description). With this
option the user can skip this restriction.{p_end}
{synopt:{opt s:tatadir}}File path. {cmd:parallel} tries to automatically identify
Stata's exe path. By using this option you will override this and force 
{cmd:parallel} to use a specific path of stata.exe.{p_end}

{syntab:Byable parallelization}
{synopt:{opt by}}Varlist. Tells the command through which observations the current dataset 
can be splitted, avoiding stories splitting over two or more clusters (for example).{p_end}
{synopt:{opt f:orce}}When using {opt by}, {cmd:parallel} checks whether if the dataset
is properly sorted. By using {opt force} the command skips this check.{p_end}

{syntab:Keeping auxiliary files}
{synopt:{opt k:eep}}Keeps auxiliary files generated by {cmd:parallel}.{p_end}
{synopt:{opt keepl:ast}}Keeps auxiliary files and remove those last time saved 
during the current session.{p_end}

{syntab:Passing Stata/Mata objects}
{synopt:{opt p:rograms}}In the case of having temporal programs loaded in the session,
using this option {cmd:parallel} passes them to the clusters.{p_end}
{synopt:{opt m:ata}}If the algorithm needs to use mata objects, this option allows
to pass to each cluster every mata object loaded in the current session (including functions).{p_end}
{synopt:{opt nog:lobal}}By default {cmd:parallel} takes into account any global macro
loaded in the sesion. If the user needs to not include globals in clusters, he
should use this option.{p_end}

{syntab:Simulation options}
{synopt:{opt s:eeds}}Numlist. With this option the user can pass an specific seed to be
used within each cluster.{p_end}
{synopt:{opt nod:ata}}Tells {cmd:parallel} that there is no data loaded and thus
should not try to split or append anything.{p_end}
{synopt:{opt randt:ype}}String. Tells parallel whether to use the current seed to
generate the seeds for each clusters (default option) or use the current datetime -datetime-
or random.org API -random.org- (please read the Description section).{p_end}

{syntab:Removing auxiliary files}
{synopt:{opt e:vent}}Integer. Specifies which executed (and stored) event's files should be removed.{p_end}
{synopt:{opt a:ll}}Tells {cmd:parallel} to remove every remanent auxiliary files generated by it
in the current directory.{p_end}
{synopt:{opt f:orce}}Forces the command to remove (apparently) in-use auxiliary files. Otherwise
these will not get deleted.{p_end}

{syntab:Other options}
{synopt:{opt t:imeout}}Integer. If a cluster hasn't start, how much time in seconds
does {cmd:parallel} has to wait until assume that there was a connection error and thus
the child process (cluster) won't start. Default value is 60.{p_end}
{synopt:{opt pr:ocessors}}Integer. If running on StataMP, sets the number of processors
each cluster should use. Default value is 0 (do nothing).{p_end}
{synopt:{opt keepu:sing}}Varlist. Subset of variables to be passed to each cluster.{p_end}

{marker description}{...}
{title:Description}

{pstd}
{cmd:parallel} allows to implement data parallelism algorithm in order to substantially
improve speed performance of it.
{p_end}

{pstd}
In order to use {cmd:parallel} it is necesary to set the number of desired clusters
with which the user wants to work with. To do this the user should use {cmd:parallel setclusters #}
syntaxis, replacing {it:#} with the desired number of clusters. Setting more clusters
than physical cores the user's computer has it is not recommended (see the {err:WARNING}
in description).
{p_end}

{pstd}
{cmd:parallel do} is the equivalent to {cmd:do}. By using this syntax, the
loaded dataset will be splitted in the number of clusters specified by {cmd:parallel setclusters}
and the {mansection U 16Do-files:do-file} will be executed independently over
each and every one of the data clusters. After all the parallel-instances stops, the datasets will be appended.
{p_end}

{pstd}
{cmd:parallel :} (as a prefix) allows to, after spliting the loaded dataset,
execute a {it:stata_cmd} over the specified number of data clusters in order to
speed up computations. Like {cmd:parallel do}, after all the parallel-instances
stops, the datasets will be appended.
{p_end}

{pstd}
Every time that {cmd:parallel} runs several auxiliary files are generated which,
after finishing, are automatically deleted. In the case that the user sets {opt k:eep}
or {opt keepl:last} the auxiliar files are kept, thus the syntax {cmd:parallel clean}
becomes handy. With {cmd:parallel clean} the user can remove the last generated
auxiliar files (default option), an specific parallel instance files (using
{it:#pll_id} number), or every stored auxiliar file (with {opt all}). For
security reasons, in-use auxiliary files will not be deleted unless the user
specifies it through the option {opt:force}, which will override not deleting
in-use auxiliary files (see the {help parallel##sandbox:sandbox} section for
more information about it)}

{pstd}
Giving {it:N} clusters, within each cluster {cmd:parallel} creates the local 
macros {it:pll_id} (equal for all the clusters) and {it:pll_instance} (ranging
from 1 up to {it:N}, equalling 1 inside the first and {it:N} inside the last).
Also the global macros {it:PLL_CLUSTERS} and {it:PLL_DIR} are available within
each cluster.
{p_end}

{pstd}
If the user needs to allow the mother instance to {cmd:break}, users can insert
the command {cmd:parallel break} (stata) and the functions 
{cmd:parallel_break()} or {cmd:_parallel_break()} (mata) in some parts of his
code. These commands/functions check whether the user has pressed the 
{cmd:-break-} key in the mother process.
{p_end}

{pstd}
As by now, {cmd:parallel} by default automatically identifies stata's
executable file path. This is necessary as it is used to run stata in batch mode
(the mainstream of the module). Either way, after some reports, that file path is not
always correctly identified; where the option {opt s:tatadir}() in {cmd:parallel setclusters}
can be used to manually set it.
{p_end}

{pstd}
In the case of pseudo-random-numbers, the module allows to pass different seed for
each cluster (child process). Moreover, if the user does not provide a numlist of
seeds, {cmd:parallel} generates its own numlist of seeds using three diferent options:
(1) based on the current seed (defaul); (2) using the current datetime as a seed to
generate each seed, restoring the original seed afterwards; or
(3) using random.org API (requires internet conection) to directly generate each
seed.
{p_end}

{pstd}
For large datasets it may be convenient to work only with the necessary variables,
this is, to pass only a group of variables to each clusters; this can be done through
the {opt keepusing} option. This option tells {cmd:parallel} what variables are
to be passed to each cluster, by doing this the memory load can be reduced.
{p_end}

{pstd}
{err:WARNINGS} {it:(a)} For each cluster {cmd:parallel} starts a new stata instance (thus
running as many processes as clusters), this way, should the user set more clusters
than cores the computer has, it is possible that the computer freezes.
{it:(b)} By this time {cmd:parallel} can not stop running the clusters by itself, what
implies that, in the case of any of the clusters starts a endless loop, stoping the
clusters should be done manually by the user by terminating them from the OS's tasks manager.
{p_end}

{marker details}{...}
{title:Details}

{pstd}
Inspired by the R library ``snow'' and to be used in multicore CPUs
, {cmd:parallel} implements parallel computing methods through an OS's shell 
scripting (using Stata in batch mode) to speedup computations by splitting the
dataset into a determined number of clusters in such a way to implement a 
{browse "http://en.wikipedia.org/wiki/Data_parallelism":data parallelism} algorithm.
{p_end}

{pstd}
The number of efficient computing clusters depends upon the number of physical
cores (CPUs) with which your computer is built, e.g. if you have a quad-core
computer, the correct cluster setting should be four. In the case of simultaneous
multithreading, such as that from
{browse "http://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html":Intel's hyper-threading technology (HTT)},
setting {cmd:parallel} following the number of processors threads, as it was expected,
hardly results into a perfect speedup scaling. In spite of it, after several tests
on HTT capable architectures, the results of implementing {cmd:parallel} according
to the machines physical cores versus it logical's shows small though significant differences.
{p_end}

{pstd}
{cmd:parallel} is especially handy when it comes to implementing loop-based
simulation models (or simply loops), Stata commands such as reshape, or any job
that (a) can be repeated through data-blocks, and (b) routines that processes big
datasets.
{p_end}

{pstd}
At this time {cmd:parallel} has been successfully tested in Windows, Unix
and MacOS for Stata versions 10 to 12.
{p_end}

{pstd}
After several tests, it has been proven that--thanks to how {cmd:parallel} has been
written--it is possible to use the algorithm in such a way that other techniques
of parallel computing can be implemented; such as Monte Carlo Simulations, 
simultaneously running models, etc.. An extensive
example through Monte Carlo Simulations is provided {browse "http://fmwww.bc.edu/repec/bocode/p/parallel.pdf":here}
{p_end}

{marker caveats}{...}
{title:Caveats}

{pstd}
When the {it:stata_cmd} or {it:do-file} {help saved_results:saves results},
as {cmd: parallel} runs Stata in {browse "http://www.stata.com/support/faqs/windows/batch-mode/":batch mode},
none of the results will be kept. This is also true for {help matrix:matrices},
{help scalar:scalars} and {help mata:mata objects}.
{p_end}

{pstd}
Although {cmd:parallel} passes-through {help program list:programs}, {help macro:macros}
and {help mata:mata objects}, in the current version it is not capable of doing the same with
{help matrix:matrices} or {help scalar:scalars}.
{p_end}

{pstd}
Including {cmd:parallel} within ado-files which contains locally-defined programs it
is not recommended due to known issues. By now parallel can not correctly
interpret these kind of programs during the loading process causing errors.
{p_end}

{marker sandbox}{...}
{title:Sandbox}

{pstd}
In order to protect a {it:pll_id} code (and thus anciliary files), once {cmd:parallel}
is called it creates a new file called {it:__pll}[{it:pll_id}]{it:sandbox} which
forbids {cmd:parallel clean} from deleting any auxiliary file used by that process
and reserves the {it:parallel_id}. Once every child process has finished, 
{cmd:parallel}'s sandbox cleans up and frees the {it:pll_id}.
{p_end}

{pstd}
If for any reason the algorithm breaks due to a flaw or crush of the system,
the sandbox file will not be deleted, but the user will be allowed to do so
manualy (moving the file(s) to the OS recycle bin) or using {cmd:parallel 
clean, force} syntax.
{p_end}

{marker examples}{...}
{title:Example 1: using prefix syntax}

{pstd}In this example we'll generate a variable containing the maximum 
blood-pressure measurement ({it:bp}) by patient.{p_end}

{pstd}Setup for a quad-core computer{p_end}
	{cmd:. sysuse bplong.dta}
	{cmd:. sort patient}
	
	{cmd:. parallel setclusters 4}

{pstd}Computes the maximum of {it:bp} for each patient. We add the option {opt by(patient)}
to tell parallel not to splitt stories.{p_end}
	{cmd:. parallel, by(patient): by patient: egen max_bp = max(bp)}
	
{pstd}Which is the ``parallel way'' to do:{p_end}

	{cmd:. by patient: egen max_bp = max(bp)}
	
{pstd}Giving you the same result.{p_end}
	
{title: Example 2: using {cmd:parallel do} syntax}

{pstd}Another usage that may get big benefits from it is implementing loop-base
simulations. Imagine that we have a model that requires looping over each and
every record of a panel-data dataset.
{p_end}

{pstd}
Using {cmd:parallel}, the proper way to do this would be using the ``parallel do''
syntax
{p_end}

	{cmd:. use mybigpanel.dta, clear}

	{cmd:. parallel setclusters 4}
	{cmd:. parallel do mymodel.do}
	
	{cmd:. collapse ...}

{pstd}where {it:mymodel.do} would look something like this{p_end}
	
	{hline 35} begin of do-file {hline 12}
        {cmd:local maxiter = _N}
        {cmd:forval i = 1/`maxiter'} {cmd:{c -(}}
                        {cmd:/* Break key check (this line is optional) */}
                        {cmd:parallel break}
			{it:...some routine...}
        {cmd:{c )-}}
	{hline 35} end of the do-file {hline 10}

{pstd}Or, in the case of using mata, this would look something like this{p_end}

	{hline 35} begin of do-file {hline 12}
        {cmd:mata:}
        {cmd:N=c("N")}
        {cmd:for(i = 1;i<=N;i++) {c -(}}
                        {cmd:/* Break key check (this line is optional) */}
                        {cmd:parallel_break()}
			{it:...some routine...}
        {cmd:{c )-}}
	{hline 35} end of the do-file {hline 10}
{marker examples}{...}
{title:Example 3: setting the right path}

{pstd}In the case of {cmd:parallel} setting the stata.exe's path wrongly, using
{cmd:parallel setstatadir} will correct the situation. So, if 
{it:"C:\Archivos de programa\Stata12/stata.exe"} is the right path we only have
to write:

	{cmd:. parallel setclusters 2, s("C:\Archivos de programa\Stata12/stata.exe")}

{marker saved_results}{...}
{title:Saved results}

{pstd}
{cmd:parallel} saves the following in {cmd:r()}:

{synoptset 20 tabbed}{...}
{p2col 5 20 24 2: Scalars}{p_end}
{synopt:{cmd:r(pll_n)}}Number of parallel clusters last used{p_end}
{synopt:{cmd:r(pll_id)}}Id of the last parallel instance executed (needed to use {cmd:parallel clean}){p_end}
{synopt:{cmd:r(pll_t_setu)}}Time took to setup (before the parallelization) and to finish the job (after the parallelization){p_end}
{synopt:{cmd:r(pll_t_calc)}}Time took to complete the parallel job{p_end}
{synopt:{cmd:r(pll_t_fini)}}Time took to appending and cleaning{p_end}
{synopt:{cmd:r(pll_t_reps)}}In the case of {opt keeptime}, the number of time measures performed.{p_end}

{p2col 5 20 24 2: Macros}{p_end}
{synopt:{cmd:r(pll_dir)}}Directory where parallel ran and stored the auxiliary files.{p_end}

{marker references}{...}

{title:References}

{phang}Luke Tierney, A. J. Rossini, Na Li and H. Sevcikova (2012). {it:snow: Simple Network of Workstations}. R package version 0.3-9. {browse "http://CRAN.R-project.org/package=snow"}{p_end}
{phang}R Core Team (2012). {it:R: A language and environment for statistical computing}. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL {browse "http://www.R-project.org/"}.{p_end}
{phang}George Vega Y (2012). {it:Introducing PARALLEL: Stata Module for Parallel Computing}. Chilean Pension Supervisor, Santiago de Chile, URL {browse "http://fmwww.bc.edu/repec/bocode/p/parallel.pdf"}.{p_end}
{phang}George Vega Y (2013). {it:Introducing PARALLEL: Stata Module for Parallel Computing}. Stata Conference 2013, New Orleans (USA), URL {browse "http://ideas.repec.org/p/boc/norl13/4.html"}.{p_end}
{phang}Haahr, M. (2006). {it:Random.org: True random number service}. Random.org. {browse "http://www.random.org/clients/http/"}.{p_end}

{title:Author}

{pstd}
George Vega Yon, Superindentencia de Pensiones. {browse "mailto:gvega@spensiones.cl"}
{p_end}

{title:Contributors}

{pstd}
Damian C. Clarke (Oxford University, England), Felix Villatoro (Superintendencia de Pensiones, Chile),
Eduardo Fajnzylber (Universidad Adolfo Ib{c a'}{c n~}ez, Chile), Eric Melse (CAREM, Netherlands),
Tom{c a'}s Rau (Universidad Cat{c o'}lica, Chile), 
Research Division (Superindentendia de Pensiones, Chile) 
and attendees to the Stata conference 2013 (New Orleans).
{p_end}

{title:{cmd:mata} source code}

{pstd}
Most of {cmd:parallel} has been programmed in {cmd:mata}. This means that, as a difference
from typical ado files, {cmd:parallel} is distributed in {cmd:lcnu} mata library
(compiled code)and thus source code can not be reached directly by users. Given
this, the help file {cmd:{help parallel_source:parallel_source.sthlp}} is included
in the package, help file which contains the source code in a fancy way.

{pstd}
In order to get acces to different sections of the source code you can follow these
links:

        Export global macros {col 58} {help parallel_source##globals_export:globals_export.mata}
        Normalize a filepath {col 58} {help parallel_source##normalizepath:normalizepath.mata}
        Remove auxiliary files {col 58} {help parallel_source##parallel_clean:parallel_clean.mata}
        Wait until a cluster finishes {col 58} {help parallel_source##parallel_finito:parallel_finito.mata}
        (on development) {col 58} {help parallel_source##parallel_for:parallel_for.mata}
        Lunch simultaneous Stata instances in batch mode {col 58} {help parallel_source##parallel_run:parallel_run.mata}
        Set the number of clusters {col 58} {help parallel_source##parallel_setclusters:parallel_setclusters.mata}
        Set the Stata EXE direcroty {col 58} {help parallel_source##parallel_setstatadir:parallel_setstatadir.mata}
        Write a dofile to be paralellized {col 58} {help parallel_source##parallel_write_do:parallel_write_do.mata}
        Export programs {col 58} {help parallel_source##program_export:program_export.mata}
        Generate random alphanum {col 58} {help parallel_source##randomid:randomid.mata}
        Write a ``diagnosis'' {col 58} {help parallel_source##write_diagnosis:write_diagnosis.mata}

{title:Also see}

{psee}
Manual: {mansection "GSM CAdvancedStatausage":{bf:[GSM] Advanced Stata usage (Mac)}},
        {mansection "GSU CAdvancedStatausage":{bf:[GSU] Advanced Stata usage (Unix)}},
        {mansection "GSW CAdvancedStatausage":{bf:[GSW] Advanced Stata usage (Windows)}}

		
{psee}
Online: Running Stata batch-mode in {browse "http://www.stata.com/support/faqs/mac/advanced-topics/#batch": Mac},
{browse "http://www.stata.com/support/faqs/unix/batch-mode/":Unix} and 
{browse "http://www.stata.com/support/faqs/windows/batch-mode/":Windows}
{p_end}
